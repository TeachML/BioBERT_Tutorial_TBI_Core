{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min',\n",
    "      jquery: 'https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from IPython.core.display import display, HTML, Javascript\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import tokenization\n",
    "from modeling import BertConfig, BertForNER\n",
    "from run_bioner import convert_examples_to_features, InputExample, AICupProcessor\n",
    "\n",
    "procr = AICupProcessor()\n",
    "label_list = procr.get_labels()\n",
    "logger = logging.getLogger('run_bioner')\n",
    "logger.setLevel(logging.WARNING)\n",
    "bert_config_file = \"pretrained_model/bert_config_bioner.json\"\n",
    "bert_config = BertConfig.from_json_file(bert_config_file)\n",
    "vocab_file = \"pretrained_model/vocab.txt\"\n",
    "processor = AICupProcessor()\n",
    "label_list = processor.get_labels()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=False)\n",
    "\n",
    "max_seq_length = 400\n",
    "device = 'cpu' # 'cuda' or 'cpu'\n",
    "init_checkpoint = \"model_step_2564.pt\"\n",
    "\n",
    "model = BertForNER(bert_config, len(label_list))\n",
    "model_params_dict = model.state_dict()\n",
    "pretrained_dict = torch.load(init_checkpoint, map_location='cpu')\n",
    "model_params_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_params_dict)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show():\n",
    "    vis_html = \"\"\"\n",
    "      <span style=\"user-select:none\">\n",
    "        Layer: <select id=\"layer\"></select>\n",
    "      </span>\n",
    "      <div id='vis'></div> \n",
    "    \"\"\"\n",
    "    display(HTML(vis_html))\n",
    "    vis_js = open(\"bertviz/head_view.js\").read()\n",
    "    params = {\n",
    "        'attention': attention_data,\n",
    "        'default_filter': \"all\"\n",
    "    }\n",
    "    display(Javascript('window.params = %s' % json.dumps(params)))\n",
    "    display(Javascript(vis_js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions_restored(model, sentence, label_id_to_name, device='cpu'):\n",
    "\n",
    "    sentence = sentence.split()\n",
    "    sent_toks, _ = tokenizer.tokenize_with_map(sentence)\n",
    "    max_seq_length = len(sent_toks) + 5\n",
    "    input_example = InputExample(1, sentence, label=['O'] * len(sentence))\n",
    "\n",
    "    tmp_feats = convert_examples_to_features([input_example, ], label_list, max_seq_length, tokenizer)\n",
    "    tmp_input_ids = torch.tensor([f.input_ids for f in tmp_feats], dtype=torch.long).to(device)\n",
    "    tmp_input_mask = torch.tensor([f.input_mask for f in tmp_feats], dtype=torch.long).to(device)\n",
    "    tmp_segment_ids = torch.tensor([f.segment_ids for f in tmp_feats], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(tmp_input_ids, tmp_segment_ids, tmp_input_mask)\n",
    "    logits = logits[0]\n",
    "    pred_labels_id = logits.argmax(dim=-1)\n",
    "    \n",
    "    if pred_labels_id.device != 'cpu':\n",
    "        pred_labels_id = pred_labels_id.cpu()\n",
    "    pred_labels_id = pred_labels_id.numpy().tolist()\n",
    "    pred_labels = [label_id_to_name[l] for l in pred_labels_id]\n",
    "    pred_labels = pred_labels[1:]\n",
    "    sent_toks = input_example.text_a\n",
    "    sent_toks_map = input_example.text_a_map\n",
    "\n",
    "    restored_tags = []\n",
    "    for i_prd, pred_ne_tag in enumerate(pred_labels):\n",
    "        if i_prd >= len(sent_toks_map):\n",
    "            break\n",
    "        if (i_prd > 0) and (sent_toks_map[i_prd - 1] == sent_toks_map[i_prd]):\n",
    "            continue\n",
    "        restored_tags.append(pred_ne_tag)\n",
    "    return list(zip(sent_toks, restored_tags))\n",
    "\n",
    "def get_model_predictions(model, sentence, label_id_to_name, device='cpu'):\n",
    "    sentence = sentence.split()\n",
    "    sent_toks, _ = tokenizer.tokenize_with_map(sentence)\n",
    "    max_seq_length = len(sent_toks) + 5\n",
    "    input_example = InputExample(1, sentence, label=['O'] * len(sentence))\n",
    "    tmp_feats = convert_examples_to_features([input_example, ], label_list, max_seq_length, tokenizer)\n",
    "    tmp_input_ids = torch.tensor([f.input_ids for f in tmp_feats], dtype=torch.long).to(device)\n",
    "    tmp_input_mask = torch.tensor([f.input_mask for f in tmp_feats], dtype=torch.long).to(device)\n",
    "    tmp_segment_ids = torch.tensor([f.segment_ids for f in tmp_feats], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(tmp_input_ids, tmp_segment_ids, tmp_input_mask)\n",
    "    logits = logits[0]\n",
    "    pred_labels_id = logits.argmax(dim=-1)\n",
    "    \n",
    "    if pred_labels_id.device != 'cpu':\n",
    "        pred_labels_id = pred_labels_id.cpu()\n",
    "    pred_labels_id = pred_labels_id.numpy().tolist()\n",
    "    pred_labels = [label_id_to_name[l] for l in pred_labels_id]\n",
    "    pred_labels = pred_labels[1:]\n",
    "    return list(zip(sent_toks, pred_labels))\n",
    "\n",
    "def get_attention(attention_probs, max_len):\n",
    "\n",
    "    \"\"\"Compute representation of attention to pass to the d3 visualization\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of attn representations with the structure:\n",
    "      {\n",
    "        'all': Sentence attention\n",
    "      }\n",
    "      where each value is a dictionary:\n",
    "      {\n",
    "        'left_text': list of source tokens, to be displayed on the left of the vis\n",
    "        'right_text': list of target tokens, to be displayed on the right of the vis\n",
    "        'attn': list of attention matrices, one for each layer. Each has shape [num_heads, source_seq_len, target_seq_len]\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    # Populate map with attn data\n",
    "    attn_dict = defaultdict(list)\n",
    "    attn_dict['all'].append(attention_probs[:, 1:max_len, 1:max_len].tolist())\n",
    "\n",
    "    results = {\n",
    "        'all': {\n",
    "            'attn': attn_dict['all'],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentence = \"FHL2 interacts with EGFR to promote glioblastoma growth.\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions =  get_model_predictions(model, sentence, label_list, device)\n",
    "    attention_probs = model.bert.encoder.layer[-1].attention.self.attention_probs[0]\n",
    "    # 12 heads, max_len, max_len\n",
    "    max_len = len(predictions) + 1\n",
    "    attention_data = get_attention(attention_probs, max_len)\n",
    "    attention_data['all']['left_text'] = list([p[0] for p in predictions])\n",
    "    attention_data['all']['right_text'] = list([p[1] for p in predictions])\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sentence = \"FHL2 interacts with EGFR to promote glioblastoma growth.\"\n",
    "# sentence = \"Stress - induced activation of Mst1 in cardiomyocytes promoted accumulation of p62 and aggresome formation, accompanied by the disappearance of autophagosomes .\"\n",
    "# sentence = \"Unexpectedly, mixed-lineage kinase domain-like (MLKL) is also required for the induction of aerobic respiration, and we further show that it is required for RIP3 translocation to meet mitochondria - localized PDC .\"\n",
    "# sentence = \"IGF - I strongly induced migration of the four cell lines through IGF - IR.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1573179980902,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "require": {
   "paths": {
    "d3": "d3.min",
    "jquery": "jquery.min"
   },
   "shim": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
